ç›®æ ‡ GPU: 0
CUDA å¯ç”¨ï¼ŒGPU æ•°é‡: 1
å°†ä½¿ç”¨ GPU: 0

å¤„ç†åœºæ™¯: /mnt/parallel/GIDigitalTwinBench/IdealSelf/LovinkDialogue
æ¨¡å‹: /mnt/parallel/models/Qwen3-30B-A3B-Instruct-2507
é…ç½®: profile=True, history=True, context=True
æµ‹è¯•æ ·æœ¬æ•°: 126
æ•°æ®åˆ†ç‰‡ 4/8: å¤„ç†æ ·æœ¬ 60 åˆ° 75 (å…± 15 ä¸ªæ ·æœ¬)
âœ… æˆåŠŸå°† 7736 ä¸ªæ ·æœ¬ä¿å­˜è‡³: /data/lingyu.li/parallel-post-train/ablation/sample_results/extracted_samples.jsonl
è®­ç»ƒæ ·æœ¬æ•°: 7736
ä½¿ç”¨ vLLM åŠ é€Ÿæ¨ç†...
ä½¿ç”¨ç¯å¢ƒå˜é‡ CUDA_VISIBLE_DEVICES=4
å¯è§GPUæ•°é‡: 1
GPU 0: NVIDIA H200, æ€»å†…å­˜: 139.80 GB, å¯ç”¨å†…å­˜: 139.80 GB
vLLMé…ç½®: gpu_memory_utilization=0.75, max_model_len=1024
åˆå§‹åŒ– vLLM å¼•æ“...
INFO 01-22 16:23:27 [utils.py:263] non-default args: {'trust_remote_code': True, 'dtype': 'bfloat16', 'max_model_len': 1024, 'gpu_memory_utilization': 0.75, 'disable_log_stats': True, 'model': '/mnt/parallel/models/Qwen3-30B-A3B-Instruct-2507'}
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
INFO 01-22 16:23:27 [model.py:530] Resolved architecture: Qwen3MoeForCausalLM
INFO 01-22 16:23:27 [model.py:1545] Using max model len 1024
INFO 01-22 16:23:27 [scheduler.py:229] Chunked prefill is enabled with max_num_batched_tokens=16384.
INFO 01-22 16:23:27 [vllm.py:630] Asynchronous scheduling is enabled.
INFO 01-22 16:23:27 [vllm.py:637] Disabling NCCL for DP synchronization when using async scheduling.
WARNING 01-22 16:23:28 [system_utils.py:136] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: CUDA is initialized
[0;36m(EngineCore_DP0 pid=87157)[0;0m INFO 01-22 16:23:37 [core.py:97] Initializing a V1 LLM engine (v0.14.0) with config: model='/mnt/parallel/models/Qwen3-30B-A3B-Instruct-2507', speculative_config=None, tokenizer='/mnt/parallel/models/Qwen3-30B-A3B-Instruct-2507', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=1024, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, enable_return_routed_experts=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False, enable_mfu_metrics=False, enable_mm_processor_stats=False, enable_logging_iteration_details=False), seed=0, served_model_name=/mnt/parallel/models/Qwen3-30B-A3B-Instruct-2507, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'compile_ranges_split_points': [16384], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 512, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False, 'assume_32_bit_indexing': True}, 'local_cache_dir': None}
[0;36m(EngineCore_DP0 pid=87157)[0;0m INFO 01-22 16:23:37 [parallel_state.py:1214] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://103.248.57.11:26171 backend=nccl
[0;36m(EngineCore_DP0 pid=87157)[0;0m INFO 01-22 16:23:38 [parallel_state.py:1425] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
[0;36m(EngineCore_DP0 pid=87157)[0;0m INFO 01-22 16:23:38 [gpu_model_runner.py:3808] Starting to load model /mnt/parallel/models/Qwen3-30B-A3B-Instruct-2507...
[0;36m(EngineCore_DP0 pid=87157)[0;0m INFO 01-22 16:23:39 [cuda.py:351] Using FLASH_ATTN attention backend out of potential backends: ('FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION')
[0;36m(EngineCore_DP0 pid=87157)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/16 [00:00<?, ?it/s]
[0;36m(EngineCore_DP0 pid=87157)[0;0m Loading safetensors checkpoint shards:   6% Completed | 1/16 [00:00<00:12,  1.17it/s]
[0;36m(EngineCore_DP0 pid=87157)[0;0m Loading safetensors checkpoint shards:  12% Completed | 2/16 [00:01<00:12,  1.11it/s]
[0;36m(EngineCore_DP0 pid=87157)[0;0m Loading safetensors checkpoint shards:  19% Completed | 3/16 [00:02<00:12,  1.02it/s]
[0;36m(EngineCore_DP0 pid=87157)[0;0m Loading safetensors checkpoint shards:  25% Completed | 4/16 [00:03<00:11,  1.02it/s]
[0;36m(EngineCore_DP0 pid=87157)[0;0m Loading safetensors checkpoint shards:  31% Completed | 5/16 [00:06<00:16,  1.46s/it]
[0;36m(EngineCore_DP0 pid=87157)[0;0m Loading safetensors checkpoint shards:  38% Completed | 6/16 [00:07<00:12,  1.28s/it]
[0;36m(EngineCore_DP0 pid=87157)[0;0m Loading safetensors checkpoint shards:  44% Completed | 7/16 [00:08<00:10,  1.18s/it]
[0;36m(EngineCore_DP0 pid=87157)[0;0m Loading safetensors checkpoint shards:  50% Completed | 8/16 [00:09<00:09,  1.16s/it]
[0;36m(EngineCore_DP0 pid=87157)[0;0m Loading safetensors checkpoint shards:  56% Completed | 9/16 [00:10<00:07,  1.13s/it]
[0;36m(EngineCore_DP0 pid=87157)[0;0m Loading safetensors checkpoint shards:  62% Completed | 10/16 [00:11<00:06,  1.08s/it]
[0;36m(EngineCore_DP0 pid=87157)[0;0m Loading safetensors checkpoint shards:  69% Completed | 11/16 [00:12<00:05,  1.08s/it]
[0;36m(EngineCore_DP0 pid=87157)[0;0m Loading safetensors checkpoint shards:  75% Completed | 12/16 [00:13<00:04,  1.05s/it]
[0;36m(EngineCore_DP0 pid=87157)[0;0m Loading safetensors checkpoint shards:  81% Completed | 13/16 [00:14<00:03,  1.06s/it]
[0;36m(EngineCore_DP0 pid=87157)[0;0m Loading safetensors checkpoint shards:  88% Completed | 14/16 [00:15<00:02,  1.07s/it]
[0;36m(EngineCore_DP0 pid=87157)[0;0m Loading safetensors checkpoint shards:  94% Completed | 15/16 [00:16<00:01,  1.04s/it]
[0;36m(EngineCore_DP0 pid=87157)[0;0m Loading safetensors checkpoint shards: 100% Completed | 16/16 [00:16<00:00,  1.21it/s]
[0;36m(EngineCore_DP0 pid=87157)[0;0m Loading safetensors checkpoint shards: 100% Completed | 16/16 [00:16<00:00,  1.05s/it]
[0;36m(EngineCore_DP0 pid=87157)[0;0m 
[0;36m(EngineCore_DP0 pid=87157)[0;0m INFO 01-22 16:23:56 [default_loader.py:291] Loading weights took 16.80 seconds
[0;36m(EngineCore_DP0 pid=87157)[0;0m INFO 01-22 16:23:56 [gpu_model_runner.py:3905] Model loading took 56.93 GiB memory and 17.224758 seconds
[0;36m(EngineCore_DP0 pid=87157)[0;0m INFO 01-22 16:24:06 [backends.py:644] Using cache directory: /data/lingyu.li/.cache/vllm/torch_compile_cache/665f936e69/rank_0_0/backbone for vLLM's torch.compile
[0;36m(EngineCore_DP0 pid=87157)[0;0m INFO 01-22 16:24:06 [backends.py:704] Dynamo bytecode transform time: 9.29 s
[0;36m(EngineCore_DP0 pid=87157)[0;0m INFO 01-22 16:24:12 [fused_moe.py:1077] Using configuration from /mnt/parallel/Qwen_30B_try/lingyu/lib/python3.12/site-packages/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H200.json for MoE layer.
[0;36m(EngineCore_DP0 pid=87157)[0;0m INFO 01-22 16:24:13 [backends.py:226] Directly load the compiled graph(s) for compile range (1, 16384) from the cache, took 1.396 s
[0;36m(EngineCore_DP0 pid=87157)[0;0m INFO 01-22 16:24:13 [monitor.py:34] torch.compile takes 10.69 s in total
[0;36m(EngineCore_DP0 pid=87157)[0;0m INFO 01-22 16:24:14 [gpu_worker.py:358] Available KV cache memory: 39.25 GiB
[0;36m(EngineCore_DP0 pid=87157)[0;0m INFO 01-22 16:24:15 [kv_cache_utils.py:1305] GPU KV cache size: 428,752 tokens
[0;36m(EngineCore_DP0 pid=87157)[0;0m INFO 01-22 16:24:15 [kv_cache_utils.py:1310] Maximum concurrency for 1,024 tokens per request: 418.70x
[0;36m(EngineCore_DP0 pid=87157)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   2%|â–         | 1/51 [00:00<00:07,  6.77it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|â–         | 2/51 [00:00<00:06,  7.41it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|â–Œ         | 3/51 [00:00<00:06,  7.53it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|â–Š         | 4/51 [00:00<00:06,  7.76it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|â–‰         | 5/51 [00:00<00:05,  8.13it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|â–ˆâ–        | 6/51 [00:00<00:05,  8.16it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|â–ˆâ–        | 7/51 [00:00<00:05,  8.26it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|â–ˆâ–Œ        | 8/51 [00:01<00:05,  7.82it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|â–ˆâ–Š        | 9/51 [00:01<00:05,  7.54it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|â–ˆâ–‰        | 10/51 [00:01<00:05,  7.26it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|â–ˆâ–ˆâ–       | 11/51 [00:01<00:05,  7.49it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|â–ˆâ–ˆâ–       | 12/51 [00:01<00:05,  7.48it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|â–ˆâ–ˆâ–Œ       | 13/51 [00:01<00:05,  7.45it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|â–ˆâ–ˆâ–‹       | 14/51 [00:01<00:04,  7.45it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|â–ˆâ–ˆâ–‰       | 15/51 [00:01<00:05,  7.09it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|â–ˆâ–ˆâ–ˆâ–      | 16/51 [00:02<00:04,  7.19it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|â–ˆâ–ˆâ–ˆâ–      | 17/51 [00:02<00:04,  7.11it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/51 [00:02<00:04,  7.36it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 19/51 [00:02<00:04,  7.26it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 20/51 [00:02<00:04,  7.47it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 21/51 [00:02<00:03,  7.57it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/51 [00:02<00:03,  7.71it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/51 [00:03<00:03,  7.83it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 24/51 [00:03<00:03,  7.81it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 25/51 [00:03<00:03,  7.49it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 26/51 [00:03<00:03,  7.63it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/51 [00:03<00:03,  7.35it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 28/51 [00:03<00:03,  7.64it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 29/51 [00:03<00:03,  7.31it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 30/51 [00:03<00:02,  7.49it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 31/51 [00:04<00:02,  7.58it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/51 [00:04<00:02,  7.85it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 33/51 [00:04<00:02,  7.24it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 34/51 [00:04<00:02,  7.32it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 35/51 [00:04<00:02,  7.34it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 36/51 [00:04<00:02,  7.15it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/51 [00:04<00:01,  7.47it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 38/51 [00:05<00:01,  7.67it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 39/51 [00:05<00:01,  7.75it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 40/51 [00:05<00:01,  7.78it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 41/51 [00:05<00:01,  7.80it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/51 [00:05<00:01,  7.48it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 43/51 [00:05<00:01,  7.63it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 44/51 [00:05<00:00,  7.29it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 45/51 [00:05<00:00,  7.60it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 46/51 [00:06<00:00,  7.71it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/51 [00:06<00:00,  7.81it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 48/51 [00:06<00:00,  7.84it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 49/51 [00:06<00:00,  7.91it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 50/51 [00:06<00:00,  7.60it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:06<00:00,  7.55it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:06<00:00,  7.55it/s]
[0;36m(EngineCore_DP0 pid=87157)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/51 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):   2%|â–         | 1/51 [00:00<00:14,  3.49it/s]Capturing CUDA graphs (decode, FULL):   4%|â–         | 2/51 [00:00<00:09,  5.14it/s]Capturing CUDA graphs (decode, FULL):   8%|â–Š         | 4/51 [00:00<00:06,  7.30it/s]Capturing CUDA graphs (decode, FULL):  10%|â–‰         | 5/51 [00:00<00:05,  7.86it/s]Capturing CUDA graphs (decode, FULL):  12%|â–ˆâ–        | 6/51 [00:00<00:05,  8.34it/s]Capturing CUDA graphs (decode, FULL):  14%|â–ˆâ–        | 7/51 [00:00<00:05,  8.70it/s]Capturing CUDA graphs (decode, FULL):  16%|â–ˆâ–Œ        | 8/51 [00:01<00:04,  8.97it/s]Capturing CUDA graphs (decode, FULL):  18%|â–ˆâ–Š        | 9/51 [00:01<00:04,  8.84it/s]Capturing CUDA graphs (decode, FULL):  20%|â–ˆâ–‰        | 10/51 [00:01<00:04,  9.03it/s]Capturing CUDA graphs (decode, FULL):  22%|â–ˆâ–ˆâ–       | 11/51 [00:01<00:04,  9.17it/s]Capturing CUDA graphs (decode, FULL):  24%|â–ˆâ–ˆâ–       | 12/51 [00:01<00:04,  9.35it/s]Capturing CUDA graphs (decode, FULL):  27%|â–ˆâ–ˆâ–‹       | 14/51 [00:01<00:03,  9.71it/s]Capturing CUDA graphs (decode, FULL):  29%|â–ˆâ–ˆâ–‰       | 15/51 [00:01<00:04,  8.71it/s]Capturing CUDA graphs (decode, FULL):  31%|â–ˆâ–ˆâ–ˆâ–      | 16/51 [00:01<00:04,  8.65it/s]Capturing CUDA graphs (decode, FULL):  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/51 [00:02<00:03,  8.90it/s]Capturing CUDA graphs (decode, FULL):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 19/51 [00:02<00:03,  8.79it/s]Capturing CUDA graphs (decode, FULL):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 20/51 [00:02<00:03,  7.88it/s]Capturing CUDA graphs (decode, FULL):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 21/51 [00:02<00:03,  8.29it/s]Capturing CUDA graphs (decode, FULL):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/51 [00:02<00:03,  7.60it/s]Capturing CUDA graphs (decode, FULL):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 24/51 [00:02<00:03,  7.15it/s]Capturing CUDA graphs (decode, FULL):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 25/51 [00:03<00:03,  7.31it/s]Capturing CUDA graphs (decode, FULL):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 26/51 [00:03<00:03,  7.77it/s]Capturing CUDA graphs (decode, FULL):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/51 [00:03<00:03,  7.99it/s]Capturing CUDA graphs (decode, FULL):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 28/51 [00:03<00:02,  8.17it/s]Capturing CUDA graphs (decode, FULL):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 29/51 [00:03<00:02,  8.41it/s]Capturing CUDA graphs (decode, FULL):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 30/51 [00:03<00:02,  8.39it/s]Capturing CUDA graphs (decode, FULL):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 31/51 [00:03<00:02,  8.49it/s]Capturing CUDA graphs (decode, FULL):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 33/51 [00:04<00:02,  8.82it/s]Capturing CUDA graphs (decode, FULL):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 34/51 [00:04<00:01,  8.99it/s]Capturing CUDA graphs (decode, FULL):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 36/51 [00:04<00:01,  8.97it/s]Capturing CUDA graphs (decode, FULL):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/51 [00:04<00:01,  8.88it/s]Capturing CUDA graphs (decode, FULL):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 38/51 [00:04<00:01,  9.01it/s]Capturing CUDA graphs (decode, FULL):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 39/51 [00:04<00:01,  9.15it/s]Capturing CUDA graphs (decode, FULL):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 40/51 [00:04<00:01,  8.87it/s]Capturing CUDA graphs (decode, FULL):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 41/51 [00:04<00:01,  9.15it/s]Capturing CUDA graphs (decode, FULL):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/51 [00:05<00:00,  9.20it/s]Capturing CUDA graphs (decode, FULL):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 43/51 [00:05<00:00,  9.35it/s]Capturing CUDA graphs (decode, FULL):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 44/51 [00:05<00:00,  9.37it/s]Capturing CUDA graphs (decode, FULL):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 45/51 [00:05<00:00,  9.12it/s]Capturing CUDA graphs (decode, FULL):  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/51 [00:05<00:00,  9.55it/s]Capturing CUDA graphs (decode, FULL):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 48/51 [00:05<00:00,  9.47it/s]Capturing CUDA graphs (decode, FULL):  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 50/51 [00:05<00:00,  9.65it/s]Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:05<00:00,  8.59it/s]
[0;36m(EngineCore_DP0 pid=87157)[0;0m INFO 01-22 16:24:28 [gpu_model_runner.py:4856] Graph capturing finished in 14 secs, took 1.48 GiB
[0;36m(EngineCore_DP0 pid=87157)[0;0m INFO 01-22 16:24:29 [core.py:273] init engine (profile, create kv cache, warmup model) took 32.32 seconds
[0;36m(EngineCore_DP0 pid=87157)[0;0m INFO 01-22 16:24:30 [vllm.py:630] Asynchronous scheduling is enabled.
INFO 01-22 16:24:30 [llm.py:347] Supported tasks: ['generate']
`torch_dtype` is deprecated! Use `dtype` instead!
âœ“ vLLM å¼•æ“åŠ è½½æˆåŠŸ
vLLM æ¨¡å¼ï¼šè·³è¿‡ transformers æ¨¡å‹åŠ è½½
  ä½¿ç”¨å• GPU æ¨¡å¼ï¼Œç›®æ ‡è®¾å¤‡: cuda:0
  ä½¿ç”¨æ•°æ®ç±»å‹: bfloat16
  å›é€€åˆ°æŒ‡å®šè®¾å¤‡åŠ è½½: cuda:0
Loading checkpoint shards:   0%|          | 0/16 [00:00<?, ?it/s]Loading checkpoint shards:   6%|â–‹         | 1/16 [00:01<00:15,  1.00s/it]Loading checkpoint shards:  12%|â–ˆâ–        | 2/16 [00:02<00:14,  1.03s/it]Loading checkpoint shards:  19%|â–ˆâ–‰        | 3/16 [00:03<00:13,  1.02s/it]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:04<00:13,  1.10s/it]Loading checkpoint shards:  31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:05<00:11,  1.08s/it]Loading checkpoint shards:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:06<00:10,  1.04s/it]Loading checkpoint shards:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:07<00:09,  1.05s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:08<00:08,  1.09s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:09<00:09,  1.16s/it]
  æŒ‡å®šè®¾å¤‡åŠ è½½ä¹Ÿå¤±è´¥: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 139.80 GiB of which 16.19 MiB is free. Including non-PyTorch memory, this process has 32.76 GiB memory in use. Process 87157 has 105.09 GiB memory in use. Process 95946 has 1.91 GiB memory in use. Of the allocated memory 32.15 GiB is allocated by PyTorch, and 113.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  ä½¿ç”¨ device_map åŠ è½½å¤±è´¥: å• GPU åŠ è½½å¤±è´¥: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 139.80 GiB of which 16.19 MiB is free. Including non-PyTorch memory, this process has 32.76 GiB memory in use. Process 87157 has 105.09 GiB memory in use. Process 95946 has 1.91 GiB memory in use. Of the allocated memory 32.15 GiB is allocated by PyTorch, and 113.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
è¯·å°è¯•è½¬æ¢æ¨¡å‹ä¸º PyTorch æ ¼å¼
  å°è¯•ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼åŠ è½½...
  å°è¯•æœ€ç®€å•çš„åŠ è½½æ–¹å¼...
Loading checkpoint shards:   0%|          | 0/16 [00:00<?, ?it/s]Loading checkpoint shards:  12%|â–ˆâ–        | 2/16 [00:00<00:01, 11.63it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:00<00:01, 11.77it/s]Loading checkpoint shards:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:00<00:00, 11.80it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:00<00:00, 11.57it/s]Loading checkpoint shards:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 10/16 [00:00<00:00, 11.65it/s]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:01<00:00, 11.35it/s]Loading checkpoint shards:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:01<00:00, 11.41it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00, 12.96it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00, 12.07it/s]
  ç®€å•æ–¹å¼åŠ è½½ä¹Ÿå¤±è´¥: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 139.80 GiB of which 14.19 MiB is free. Including non-PyTorch memory, this process has 32.76 GiB memory in use. Process 87157 has 105.09 GiB memory in use. Process 95946 has 1.91 GiB memory in use. Of the allocated memory 32.25 GiB is allocated by PyTorch, and 11.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/mnt/parallel/Qwen_30B_try/improvement_3/inference.py", line 1453, in process_scenario
    raise RuntimeError(f"å• GPU åŠ è½½å¤±è´¥: {last_error}\nè¯·å°è¯•è½¬æ¢æ¨¡å‹ä¸º PyTorch æ ¼å¼")
RuntimeError: å• GPU åŠ è½½å¤±è´¥: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 139.80 GiB of which 16.19 MiB is free. Including non-PyTorch memory, this process has 32.76 GiB memory in use. Process 87157 has 105.09 GiB memory in use. Process 95946 has 1.91 GiB memory in use. Of the allocated memory 32.15 GiB is allocated by PyTorch, and 113.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
è¯·å°è¯•è½¬æ¢æ¨¡å‹ä¸º PyTorch æ ¼å¼

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/parallel/Qwen_30B_try/improvement_3/inference.py", line 1567, in process_scenario
    model = model.to(target_device)
            ^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/parallel/Qwen_30B_try/lingyu/lib/python3.12/site-packages/transformers/modeling_utils.py", line 4343, in to
    return super().to(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/parallel/Qwen_30B_try/lingyu/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1371, in to
    return self._apply(convert)
           ^^^^^^^^^^^^^^^^^^^^
  File "/mnt/parallel/Qwen_30B_try/lingyu/lib/python3.12/site-packages/torch/nn/modules/module.py", line 930, in _apply
    module._apply(fn)
  File "/mnt/parallel/Qwen_30B_try/lingyu/lib/python3.12/site-packages/torch/nn/modules/module.py", line 930, in _apply
    module._apply(fn)
  File "/mnt/parallel/Qwen_30B_try/lingyu/lib/python3.12/site-packages/torch/nn/modules/module.py", line 930, in _apply
    module._apply(fn)
  [Previous line repeated 4 more times]
  File "/mnt/parallel/Qwen_30B_try/lingyu/lib/python3.12/site-packages/torch/nn/modules/module.py", line 957, in _apply
    param_applied = fn(param)
                    ^^^^^^^^^
  File "/mnt/parallel/Qwen_30B_try/lingyu/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1357, in convert
    return t.to(
           ^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 139.80 GiB of which 14.19 MiB is free. Including non-PyTorch memory, this process has 32.76 GiB memory in use. Process 87157 has 105.09 GiB memory in use. Process 95946 has 1.91 GiB memory in use. Of the allocated memory 32.25 GiB is allocated by PyTorch, and 11.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/parallel/Qwen_30B_try/improvement_3/inference.py", line 1573, in process_scenario
    raise RuntimeError(f"æ‰€æœ‰åŠ è½½æ–¹å¼éƒ½å¤±è´¥ã€‚æœ€åé”™è¯¯: {last_error}\nè¯·å°è¯•è½¬æ¢æ¨¡å‹ä¸º PyTorch æ ¼å¼")
RuntimeError: æ‰€æœ‰åŠ è½½æ–¹å¼éƒ½å¤±è´¥ã€‚æœ€åé”™è¯¯: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 139.80 GiB of which 14.19 MiB is free. Including non-PyTorch memory, this process has 32.76 GiB memory in use. Process 87157 has 105.09 GiB memory in use. Process 95946 has 1.91 GiB memory in use. Of the allocated memory 32.25 GiB is allocated by PyTorch, and 11.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
è¯·å°è¯•è½¬æ¢æ¨¡å‹ä¸º PyTorch æ ¼å¼

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/parallel/Qwen_30B_try/improvement_3/inference.py", line 2029, in <module>
    main()
  File "/mnt/parallel/Qwen_30B_try/improvement_3/inference.py", line 2002, in main
    process_scenario(
  File "/mnt/parallel/Qwen_30B_try/improvement_3/inference.py", line 1592, in process_scenario
    raise RuntimeError(error_msg)
RuntimeError: 
æ‰€æœ‰åŠ è½½æ–¹å¼éƒ½å¤±è´¥ã€‚é”™è¯¯: æ‰€æœ‰åŠ è½½æ–¹å¼éƒ½å¤±è´¥ã€‚æœ€åé”™è¯¯: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 139.80 GiB of which 14.19 MiB is free. Including non-PyTorch memory, this process has 32.76 GiB memory in use. Process 87157 has 105.09 GiB memory in use. Process 95946 has 1.91 GiB memory in use. Of the allocated memory 32.25 GiB is allocated by PyTorch, and 11.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
è¯·å°è¯•è½¬æ¢æ¨¡å‹ä¸º PyTorch æ ¼å¼

æ¨¡å‹æ–‡ä»¶æ£€æŸ¥ç»“æœ:
  - Safetensors æ–‡ä»¶: 0 ä¸ª
  - PyTorch æ–‡ä»¶: 0 ä¸ª

å»ºè®®çš„è§£å†³æ–¹æ¡ˆï¼š
1. å°† safetensors è½¬æ¢ä¸º PyTorch æ ¼å¼:
   python -c "from transformers import AutoModel; model = AutoModel.from_pretrained('/mnt/parallel/models/Qwen3-30B-A3B-Instruct-2507', trust_remote_code=True); model.save_pretrained('/mnt/parallel/models/Qwen3-30B-A3B-Instruct-2507_pytorch', safe_serialization=False)"

2. æ›´æ–°åº“ç‰ˆæœ¬:
   pip install --upgrade safetensors transformers accelerate

3. ä½¿ç”¨å• GPU æ¨¡å¼ï¼ˆä¸ä½¿ç”¨ --use_multi_gpuï¼‰

[rank0]:[W122 16:24:56.998053542 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
ERROR 01-22 16:24:56 [core_client.py:610] Engine core proc EngineCore_DP0 died unexpectedly, shutting down client.
